<h1 align="center">
  <a href="https://openreview.net/pdf?id=DDIGCk25BO" target="_blank">
    Robust Automatic Modulation Classification with Fuzzy Regularizationq
  </a>
</h1>

<p align="center">
  <a href="https://xinyanliang.github.io/"><u>Xinyan Liang</u></a><sup>1</sup>, 
  <u>Ruijie Sang</u><sup>1</sup>, 
  <a href="https://dig.sxu.edu.cn/qyh/"><u>Yuhua Qian</u></a><sup>1</sup>, 
  <u>Qian Guo</u><sup>2</sup>, 
  <u>Feijiang Li</u><sup>1</sup>,
  <u>Liang Du</u><sup>1</sup>
</p>

<p align="center">
  <sup>1</sup>Shanxi University, <sup>2</sup>Taiyuan University of Science and Technology
</p>

<p align="center">
  <a href="https://openreview.net/pdf?id=DDIGCk25BO">
    <img src="https://img.shields.io/badge/OpenReview-gray?style=flat&logo=OpenReview">
  </a>
</p>



# Abstract
Automatic modulation classification (AMC) serves as a foundational pillar for cognitive radio systems, enabling critical functionalities including dynamic spectrum allocation, non-cooperative signal surveillance, and adaptive waveform optimization. However, practical deployment of
AMC faces a fundamental challenge: prediction ambiguity arising from intrinsic similarity among
modulation schemes and exacerbated under low signal-to-noise ratio (SNR) conditions. This phenomenon manifests as near-identical probability
distributions across confusable modulation types, significantly degrading classification reliability.
To address this, we propose Fuzzy Regularizationenhanced AMC (FR-AMC), a novel framework
that integrates uncertainty quantification into the
classification pipeline. The proposed FR has three
features: (1) Explicitly model prediction ambiguity during backpropagation, (2) dynamic sample
reweighting through adaptive loss scaling, (3) encourage margin maximization between confusable modulation clusters. Experimental results
on benchmark datasets demonstrate that the FR
achieves superior classification accuracy and robustness compared to compared methods, making
it a promising solution for real-world spectrum
management and communication applications.

# ğŸ§± Architecture
``` 
home
â”œâ”€â”€ amr/
â”‚   â”œâ”€â”€ dataloaders/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â”œâ”€â”€ networks/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ draw.py
â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   â”‚   â”œâ”€â”€ log_train_info.py
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ solver.py
â”‚   â”‚   â”œâ”€â”€ static.py
â”œâ”€â”€ Data/
â”œâ”€â”€ train_DAELSTM/
â”‚   â”œâ”€â”€ DAELSTM_configs/
â”‚   â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ DAELSTM_configs.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ train_Cen.py
â”œâ”€â”€ train_FEAT/
â”œâ”€â”€ train_MCLDNN/
â”œâ”€â”€ train_ThreeStream/
```
# ğŸ› ï¸ Previous Preparation
## 1.Clone this repository and navigate to source folder
``` bash
cd AMCFR
``` 

## 2.Build Environment
``` bash
echo "Creating conda environment"
conda create -n AMCFR python=3.10
conda activate AMCFR

echo "Installing dependencies"
pip install -r requirements.txt
``` 
## 3.Download the dataset
All of our datasets are public datasets, and you can obtain the [datasets](https://www.deepsig.ai/) you need at this location. 
Download the dataset to the "Data/" folder.


# ğŸš€ Quick Start
## 1.Modify the dataset address

Navigate to the 'amr/dataloaders/' directory and select the corresponding dataset loader file (e.g., 'dataloader_2016aData.py').
Locate the 'data_path' variable and update its value to the path where your dataset is stored on your local machine.
```
class SignalDataLoader(object):
    def __init__(self, mod_type=[],snr_type=[],scal=0):
        mods = ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16','QAM64', 'QPSK', 'WBFM']
        
        data_path=r'/home/sangruijie_qyh/Data/Signal/RML2016.10a_dict.pkl'
       
        data = pickle.load(open(data_path, 'rb'), encoding='iso-8859-1')
        data_keys=data.keys()
```
## 2.Model configuration
é€‰æ‹©ä¸€ä¸ªä½ æƒ³è®­ç»ƒçš„æ¨¡å‹ï¼Œä¾‹å¦‚"DAELSTM"æ¨¡å‹ï¼Œè¿›å…¥æ¨¡å‹å¯¹åº”çš„å­æ–‡ä»¶å¤¹"train_DAELSEM/DAELSTM_configs"è¿›è¡Œå‚æ•°é…ç½®ã€‚DAELSTM_train.yamlæ–‡ä»¶å¯¹åº”train.pyæ–‡ä»¶ï¼›DAELSTM_train_Cen.yamlæ–‡ä»¶å¯¹åº”train_Cen.pyæ–‡ä»¶ã€‚ï¼ˆæ­¤å¤„æˆ‘ä»¬ä¿ç•™ä¸¤ä¸ªè®­ç»ƒè„šæœ¬æ˜¯å› ä¸ºFRæŸå¤±æ¶‰åŠå‚æ•°ï¼Œè€Œå…¶ä½™éƒ¨åˆ†æŸå¤±ä¸æ¶‰åŠå‚æ•°é€‰æ‹©ã€‚ï¼‰
### (1) ä¿®æ”¹DAELSTM_config.pyæ–‡ä»¶
å°†é…ç½®æ–‡ä»¶"DAELSTM_train.yaml"åœ°å€æ›´æ¢ä¸ºè¯¥æ–‡ä»¶åœ¨æ‚¨è®¾å¤‡çš„å®é™…åœ°å€ã€‚
```
def get_cfgs():
    cfgs = get_cfg_defaults()
    parser = argparse.ArgumentParser(description='AMR HyperParameters')
    parser.add_argument('--config', type=str, default='/home/sangruijie_qyh/Code/TransGroupNet-FR/Roubust_AMCFR/train_DAELSTM/DAELSTM_configs/DAELSTM_train.yaml',
                        help='type of config file. e.g. resnet_cfo (Resnet_configs/resnet_cfo.yaml)')
    args = parser.parse_args()
    cfgs.merge_from_file(args.config)
    return cfgs
```
### (2) ä¿®æ”¹"DAELSTM_train.yaml"æ–‡ä»¶
åœ¨è¯¥æ–‡ä»¶ä¸­methonå¯¹åº”æ‰€ç”¨æ¨¡å‹æ¶æ„ï¼ˆ"./amr/models/networks/DAELSTM"ï¼‰,networkè¡¨ç¤ºå…·ä½“ç½‘ç»œã€‚ï¼ˆ"DAELSTM.py" or 
"DAELSTM_1024.py");trainè¡¨ç¤ºè¿›è¡Œè®­ç»ƒæˆ–æ˜¯åªè¿›è¡Œæµ‹è¯•ï¼›scalæ§åˆ¶æ˜¯å¦æ·»åŠ å™ªå£°ï¼›
```yaml
method: 'DAELSTM'
train: True
dataset: '2016aData'
mod_type: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16','QAM64', 'QPSK', 'WBFM']
snr_type: [0,2,4,6,8,10,12,14,16,18]
scal : 0    #0,0.2,0.4,0.6
workers: 8
seed: 1
gpu: 7
cpu: False
params:
    "network": "DAELSTM"
    "loss": "loss_FG"
    "loss_c": 2
    "loss_t": 2
    "loss_alp": 0.01
    "batch_size": 128
    "epochs": 200
    "lr": 5e-3
    "lr_decay": 0.
    "weight_decay": 0.
    "early_stop": False
    "Xmode": [{"type":"AP","options":{"IQ_norm":False, "zero_mask":True}}]
```
### (3)ä¿®æ”¹å¯»å‚èŒƒå›´
å‡å¦‚æ‚¨æ˜¯ä¸€ä¸ªkåˆ†ç±»é—®é¢˜ï¼Œcçš„å–å€¼å°±æ˜¯[1,k],tè¡¨ç¤ºFRæŸå¤±å’Œäº¤å‰ç†µæŸå¤±ä¹‹é—´çš„æƒé‡ã€‚æ›´å¤šå‚æ•°ç»†èŠ‚å¯è§è®ºæ–‡4.6èŠ‚ã€‚
```
if __name__ == '__main__':
    c = [5]
    t = [ 0.0001 ]
    best_acc=0
    for c1 in c:
        for t1 in t:
            cfgs = get_cfgs()
            main(cfgs,c1,t1)
```

## 3.Train
### è¿è¡Œå¸¦æœ‰å‚æ•°çš„æŸå¤±
```bash
cd './AMCFR/train_DAELSTM'
python train.py
```
### è¿è¡Œæ— å‚æ•°æŸå¤±
```bash
cd './AMCFR/train_DAELSTM'
python train_Cen.py
```
## 4.Checking the results
åœ¨ä»£ç è¿è¡Œå®Œæ¯•åï¼Œç¨‹åºä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª"results/"æ–‡ä»¶å¤¹ï¼Œä¿å­˜æœ€ä¼˜æ¨¡å‹å‚æ•°ã€è®­ç»ƒä¿¡æ¯ä»¥åŠæ··æ·†çŸ©é˜µã€‚
```
â”œâ”€â”€ train_DAELSTM/
â”‚   â”œâ”€â”€ DAELSTM_configs/
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â”œâ”€â”€ DAELSTM/
â”‚   â”‚   â”‚   â”œâ”€â”€ DatasetName/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lossName/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ paramers/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ draws/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train_info.csv
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ test_info.csv
```
# ğŸ”„ Select other models or datasets
## Change the dataset
å¦‚æœä½ è¦ä½¿ç”¨ä¸€ä¸ªæ–°çš„æ•°æ®é›†

(1) å°†æ•°æ®é›†ä¸‹è½½åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ä¸­ã€‚

(2) åœ¨'./Roubust_AMCFR/amr/dataloaders'ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®å¤„ç†æ–‡ä»¶"dataloader_Newdataset",å¹¶å°†è¾“å‡ºç«¯å£ä¸å·²æœ‰è¾“å‡ºç«¯å£ä¿æŒä¸€è‡´ï¼Œä¾‹å¦‚"dataloader_2016aData.py"æ–‡ä»¶ã€‚

(3) å¯¹éœ€è¦è¿è¡Œæ¨¡å‹çš„configæ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œä¾‹å¦‚"./Roubust_AMCFR/train_DAELSTM/DAELSTM_configs/DAELSTM_train.yaml"æ–‡ä»¶ä¸­ï¼Œå°†"dataset:"è®¾ç½®ä¸º'Newdataset'.

## Change the model
å¦‚æœä½ è¦ä½¿ç”¨ä¸€ä¸ªæ–°çš„æ¨¡å‹

(1) å°†æ¨¡å‹ä¿å­˜åœ¨"./Roubust_AMCFR/amr/models/networks"æ–‡ä»¶å¤¹ä¸­ã€‚

(2) åˆ›å»º"train_Newmodel"å­æ–‡ä»¶å¤¹ï¼Œç±»ä¼¼"train_DAELSTM"æ–‡ä»¶å¤¹ã€‚

(3) ä¿®æ”¹"model_config.py"æ–‡ä»¶ï¼Œä»¥åŠ"model_train.yaml"æ–‡ä»¶.(ä¾‹å¦‚"DAELSTM_config.py"æ–‡ä»¶å’Œ"DAELSTM_train.yaml"æ–‡ä»¶)

# ğŸ“ Citation
Please consider citing our paper if our code and benchmark are useful:

# ğŸ™ Acknowledgement

# ğŸ“ª Contact
For any question, feel free to email <span style="background-color:#f2f2f2; border-radius:6px; padding:2px 6px; font-family:monospace;">
  sangrj66@163.com
</span>




